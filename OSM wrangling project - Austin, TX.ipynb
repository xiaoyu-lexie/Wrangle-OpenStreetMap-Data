{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project of Austin, TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Map Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Austin, TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.openstreetmap.org/node/1801308037#map=11/30.2715/-97.7436"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose Austin, TX because it's the next travelling city I plan to visit. However, although I only looked for city of Austin, the osm file downloaded has included cities around Austin. The whole file looks too big to run locally in my computer. So I decide to extract a sample from original one by using code given on Project Detail page, and name it \"Austin_split.osm'. Then I extract a smaller sample from 'Austin_split.osm' and name it \"sample.osm'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import os\n",
    "from hurry.filesize import size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems found in the OSM dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The values like 'atm' and 'bench' are the value of 'k' attribute, and also could be the value of 'v' attribute when value of 'k' attribute is 'amenity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'amenity': {'atm', 'bench'},\n",
       "             'atm': {'yes'},\n",
       "             'bench': {'no', 'yes'}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amenity_set = defaultdict(set) #it will show that \"atm\" and \"bench\" could be either keys of dict or values of key\n",
    "\n",
    "for _,element in ET.iterparse(\"Austin_split.osm\", events = (\"start\",)):\n",
    "    if element.tag == \"node\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            #make tag.attrib['k'] be the keys in dict, and tag.attrib['v'] be the value of key\n",
    "            if tag.attrib['k'] == 'atm' or tag.attrib['k'] == 'bench' or tag.attrib['v'] == 'atm' or tag.attrib['v'] == 'bench':\n",
    "                amenity_set[tag.attrib['k']].add(tag.attrib['v'])\n",
    "            \n",
    "amenity_set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The city names in \"node\" are not in consistent format, like 'Austin' and 'Austin, TX', 'Dripping Springs' and 'Dripping Springs, Tx'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austin',\n",
       " 'Austin, TX',\n",
       " 'Buda',\n",
       " 'Cedar Park',\n",
       " 'Creedmoor',\n",
       " 'Dripping Springs',\n",
       " 'Dripping Springs, Tx',\n",
       " 'Lakeway',\n",
       " 'Manchaca',\n",
       " 'Pflugerville'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_name_set = set() #to show all non-repeated city names\n",
    "\n",
    "for _,element in ET.iterparse(\"Austin_split.osm\", events = (\"start\",)):\n",
    "    if element.tag == \"node\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == 'addr:city':\n",
    "                city_name_set.add(tag.attrib['v'])\n",
    "                \n",
    "city_name_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The street names are sometimes in abbreviation formats, like 'S 1st St, Suite 104', 'N HWY 183' and 'FM 535'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 'trigger:zip_left' and 'tiger:zip_left_1' are not same in some cases, for example:\n",
    "    \n",
    "       <tag k=\"tiger:zip_left\" v=\"78617\" />\n",
    "       <tag k=\"tiger:zip_left_1\" v=\"78612\" />\n",
    "       <tag k=\"tiger:zip_left_2\" v=\"78617\" />\n",
    "       <tag k=\"tiger:zip_right\" v=\"78617\" />\n",
    "       <tag k=\"tiger:zip_right_1\" v=\"78612\" />\n",
    "       <tag k=\"tiger:zip_right_2\" v=\"78617\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Some of the street name is repeated and divided into several segments, for example:\n",
    "     \n",
    "       <tag k=\"highway\" v=\"residential\" />\n",
    "       <tag k=\"name\" v=\"East 22nd Street\" />\n",
    "       <tag k=\"surface\" v=\"asphalt\" />\n",
    "       <tag k=\"tiger:cfcc\" v=\"A41\" />\n",
    "       <tag k=\"tiger:county\" v=\"Travis, TX\" />\n",
    "       <tag k=\"tiger:name_base\" v=\"22nd\" />\n",
    "       <tag k=\"tiger:name_direction_prefix\" v=\"E\" />\n",
    "       <tag k=\"tiger:name_type\" v=\"St\" />\n",
    "       <tag k=\"tiger:reviewed\" v=\"no\" />\n",
    "       <tag k=\"tiger:zip_left\" v=\"78722\" />\n",
    "       <tag k=\"tiger:zip_right\" v=\"78722\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The 'name' and 'name_1' in the 'tag' from same 'way' tag are not same in some cases like: \n",
    "\n",
    "       <tag k=\"name\" v=\"Lakewood Drive\" />\n",
    "       <tag k=\"name_1\" v=\"County Road 307\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revise of Problem 2 about city names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will unify city names under both \"node\" and \"way\" in the format of \"CityName\". That is applied in \"Austin_split.osm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys are inconsistant city names, values are right ones\n",
    "mapping = { \"Austin, TX\": \"Austin\",\n",
    "            \"Austin, Tx\": \"Austin\",\n",
    "            \"Dripping Springs, Tx\": \"Dripping Springs\",\n",
    "            \"Pflugerville, TX\": \"Pflugerville\", \n",
    "            \"Westlake Hills, TX\": \"West Lake Hills\",\n",
    "            \"austin\": \"Austin\",\n",
    "            \"Ste 128, Austin\": \"Austin\",\n",
    "            \"Austin;TX;USA\": \"Austin\",\n",
    "            \"Dripping Springs TX\": \"Dripping Springs\",\n",
    "            \"N Austin\": \"Austin\"\n",
    "            }\n",
    "\n",
    "def get_element():\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/changing-attribute-value-in-xml/44575/6\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(\"Austin_split.osm\", events=('start', ))\n",
    "    _, root = next(context)\n",
    "    for event,element in context:\n",
    "        if element.tag == \"node\" or element.tag == 'way':\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:city':\n",
    "                    if tag.attrib['v'] in mapping.keys(): #if attrib['v'] matches the keys in mapping:\n",
    "                        tag.set('v', mapping[tag.attrib['v']]) #replace keys by values in the xml\n",
    "\n",
    "        yield element \n",
    "        root.clear()\n",
    "    \n",
    "SAMPLE_FILE = \"first_Austin_edited.osm\"\n",
    "    \n",
    "with open(SAMPLE_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # this is where the output of yield is called on the \n",
    "    for i, element in enumerate(get_element()):\n",
    "        output.write(ET.tostring(element, encoding='utf-8')) #for each yielded element, write its all attributes and child tags \n",
    "\n",
    "    output.write('</osm>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revise of Problem 3 about street names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nonstandard street names not only happen when 'k' value equals to 'addr:street', but also appear when 'k' equals to 'name' under 'way' tag. I will replace all words that match keys of the following mapping dictionary by the values of keys. So 'S 1st St, Suite 104' will be revised to 'South 1st Street, Suite 104'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"ave\": \"Avenue\",\n",
    "           \"blvd\": \"Boulevard\",\n",
    "           \"ct\": \"Court\",\n",
    "           \"cv\": \"Cove\", \n",
    "           \"dr\": \"Drive\",\n",
    "           \"dr.\": \"Drive\",\n",
    "           \"ln\": \"Lane\",\n",
    "           \"rd\": \"Road\",\n",
    "           \"st\": \"Street\",\n",
    "           \"st.\": \"Street\",\n",
    "           \"pl\": \"Place\",\n",
    "           \"trl\": \"Trail\",\n",
    "           \"ps\": \"Pass\",\n",
    "           \"pkwy\": \"Parkway\",\n",
    "           \"s\": \"South\",\n",
    "           \"n\": \"North\",\n",
    "           \"e\": \"East\",\n",
    "           \"w\": \"West\",\n",
    "           \"fm\": \"Farm-to-Market Road\",\n",
    "           \"hwy\": \"Highway\",\n",
    "           \"ih\": \"Interstate Highway\",\n",
    "           \"i\": \"Interstate Highway\",\n",
    "           \"rr\": \"Ranch Road\"\n",
    "          }\n",
    "\n",
    "def get_element():  # to yield every element that has been revised in the xml\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/changing-attribute-value-in-xml/44575/6\n",
    "    \"\"\"\n",
    "    context = ET.iterparse(\"first_Austin_edited.osm\", events=('start', ))\n",
    "    _, root = next(context)\n",
    "    for event,element in context:\n",
    "        if element.tag == \"node\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'addr:street':  \n",
    "                    v_without_comma = tag.attrib['v'].replace(\",\", \"\") \n",
    "                    #change 'S 1st St, Suite 104' to 'S 1st St Suite 104' so that 'St' can be replaced smoothly\n",
    "                    v_list = v_without_comma.split()\n",
    "                    for item in v_list:\n",
    "                        if item.lower() in mapping.keys(): #if any words of string mathes keys of mapping:\n",
    "                            new_v = tag.attrib['v'].replace(item, mapping[item.lower()],1) #replace the kays by values\n",
    "                            tag.set('v', new_v) #revise it in xml\n",
    "                            \n",
    "        elif element.tag == \"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == 'name' or tag.attrib['k'] == 'addr:street': #two ways to give information of street names\n",
    "                    v_without_comma = tag.attrib['v'].replace(\",\", \"\")\n",
    "                    v_list = v_without_comma.split()\n",
    "                    for item in v_list:\n",
    "                        if item.lower() in mapping.keys():\n",
    "                            new_v = tag.attrib['v'].replace(item, mapping[item.lower()],1)\n",
    "                            tag.set('v', new_v)\n",
    "                   \n",
    "\n",
    "\n",
    "        yield element\n",
    "        root.clear()\n",
    "    \n",
    "SAMPLE_FILE = \"second_Austin_edited.osm\"\n",
    "    \n",
    "with open(SAMPLE_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # this is where the output of yield is called on the \n",
    "    for i, element in enumerate(get_element()):\n",
    "        output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from csv to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data from xml to csv\n",
    "\n",
    "%run data.py      #exactly same code in Case Study Lesson 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create database file from csv\n",
    "\"\"\"\n",
    "\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/creating-db-file-from-csv-files-with-non-ascii-unicode-characters/174958/7\n",
    "\"\"\"\n",
    "\n",
    "#part 1: Create Database\n",
    "sqlite_file = 'Austin.db'\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "conn.commit()\n",
    "\n",
    "#part 2: Create tables\n",
    "cur.execute('''\n",
    "    CREATE TABLE nodes(id INTEGER PRIMARY KEY, \n",
    "    user TEXT, \n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    lat DOUBLE PRECISION,\n",
    "    lon DOUBLE PRECISION,\n",
    "    timestamp TIMESTAMP,\n",
    "    changeset INTEGER)\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "    CREATE TABLE nodes_tags(id INTEGER references node (id), \n",
    "    key TEXT, \n",
    "    value TEXT,\n",
    "    type TEXT)\n",
    "''')\n",
    "\n",
    "\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways(id INTEGER PRIMARY KEY, \n",
    "    user TEXT, \n",
    "    uid INTEGER,\n",
    "    version TEXT,\n",
    "    timestamp TIMESTAMP,\n",
    "    changeset INTEGER)\n",
    "''')\n",
    "\n",
    "\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways_tags(id INTEGER references way (id), \n",
    "    key TEXT, \n",
    "    value TEXT,\n",
    "    type TEXT)\n",
    "''')\n",
    "\n",
    "cur.execute('''\n",
    "    CREATE TABLE ways_nodes(id INTEGER references way (id), \n",
    "    node_id INTEGER, \n",
    "    position INTEGER)\n",
    "''')\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "#part 3: Read the csv and insert data\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['lat'], i['lon'], i['timestamp'], \\\n",
    "              i['changeset']) for i in dr]\n",
    "    \n",
    "# insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, user, uid, version, lat, lon, timestamp, changeset) \\\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "    \n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin)\n",
    "    to_db = [(i['id'], i['key'],i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['user'].decode(\"utf-8\"), i['uid'], i['version'], i['timestamp'], i['changeset']) for i in dr]\n",
    "    \n",
    "cur.executemany(\"INSERT INTO ways(id, user, uid, version, timestamp, changeset) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "    \n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['key'],i['value'].decode(\"utf-8\"), i['type']) for i in dr]\n",
    "    \n",
    "cur.executemany(\"INSERT INTO ways_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "conn.commit()\n",
    "    \n",
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) \n",
    "    to_db = [(i['id'], i['node_id'],i['position']) for i in dr]\n",
    "    \n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin.db...............................: 60M  \n",
      "Austin_split.osm........................: 112M \n",
      "data.py.................................: 7K   \n",
      "first_Austin_edited.osm.................: 136M \n",
      "nodes.csv...............................: 47M  \n",
      "nodes_tags.csv..........................: 1015K\n",
      "OSM wrangling project - Austin, TX.ipynb: 25K  \n",
      "sample.osm..............................: 11M  \n",
      "schema.py...............................: 2K   \n",
      "schema.pyc..............................: 1K   \n",
      "second_Austin_edited.osm................: 158M \n",
      "ways.csv................................: 3M   \n",
      "ways_nodes.csv..........................: 13M  \n",
      "ways_tags.csv...........................: 5M   \n",
      "OSM wrangling project - Austin, TX-checkpoint.ipynb: 25K  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "    Reference:\n",
    "    https://discussions.udacity.com/t/display-files-and-their-sizes-in-directory/186741/13\n",
    "\"\"\"   \n",
    "    \n",
    "dirpath = 'C:/Users/data expert/Desktop/Austin Project'\n",
    "\n",
    "files_list = []\n",
    "for path, dirs, files in os.walk(dirpath):\n",
    "    files_list.extend([(filename, size(os.path.getsize(os.path.join(path, filename)))) for filename in files])\n",
    "\n",
    "for filename, size in files_list:\n",
    "    print '{:.<40s}: {:5s}'.format(filename,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(901,)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "conn = sqlite3.connect('Austin.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT COUNT(DISTINCT(all_uid.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) as all_uid')\n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512771,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cur.execute('SELECT COUNT(*) FROM nodes')\n",
    "results = cur.fetchone()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54027,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cur.execute('SELECT COUNT(*) FROM ways')\n",
    "results = cur.fetchone()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Austin',),\n",
      " (u'Bee Cave',),\n",
      " (u'Buda',),\n",
      " (u'Cedar Creek',),\n",
      " (u'Cedar Park',),\n",
      " (u'Creedmoor',),\n",
      " (u'Del Valle',),\n",
      " (u'Dripping Springs',),\n",
      " (u'Lakeway',),\n",
      " (u'Manchaca',),\n",
      " (u'Manor',),\n",
      " (u'Pflugerville',),\n",
      " (u'West Lake Hills',)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT DISTINCT city_union.value FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) as city_union \\\n",
    "WHERE city_union.key = 'city' \\\n",
    "GROUP BY city_union.value\")\n",
    "                \n",
    "\n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'burger', 15), (u'pizza', 8), (u'sandwich', 7)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT tags.value, COUNT(*) as Num FROM \\\n",
    "            (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) as tags \\\n",
    "            WHERE tags.key = 'cuisine' \\\n",
    "            GROUP BY tags.value \\\n",
    "            ORDER BY Num DESC \\\n",
    "            LIMIT 3\")\n",
    "             \n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 leisure place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pitch', 86), (u'park', 48), (u'playground', 12)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT tags.value, COUNT(*) as Num FROM \\\n",
    "            (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) as tags \\\n",
    "            WHERE tags.key = 'leisure' \\\n",
    "            GROUP BY tags.value \\\n",
    "            ORDER BY Num DESC \\\n",
    "            LIMIT 3\")\n",
    "             \n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviewed = 'no' and 'name' not equal to 'name_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I explore the 'ways_tags' dataset, I found a interesting 'k' value: 'reviewed', whoes values coule be either 'yes' and 'no'. I wonder if there is some relations between reviewed = 'no' and some problematic data like 'name' not equal to 'name_1'. Let's explore and prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7148d810>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create view that contains all distinct id of 'name' not equal to 'name_1'\n",
    "\n",
    "cur.execute(\"CREATE VIEW name_name1_not_equal as\\\n",
    "            SELECT DISTINCT name_one.id, name_one.value, name.value \\\n",
    "            FROM (SELECT * FROM ways_tags WHERE ways_tags.key = 'name_1') as name_one \\\n",
    "            LEFT JOIN\\\n",
    "            (SELECT * FROM ways_tags WHERE ways_tags.key = 'name') as name \\\n",
    "            on name_one.id = name.id \\\n",
    "            WHERE name_one.value != name.value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(67,)]\n"
     ]
    }
   ],
   "source": [
    "# count how many distinct id having 'name' not equal to 'name_1'\n",
    "cur.execute(\"SELECT COUNT (*) FROM name_name1_not_equal \")\n",
    "                     \n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7148d810>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create view that contains all distinct id of reviewed = 'no'\n",
    "\n",
    "cur.execute(\"CREATE VIEW reviewed_is_no as\\\n",
    "            SELECT * FROM ways_tags WHERE ways_tags.key = 'reviewed' AND ways_tags.value = 'no'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(57,)]\n"
     ]
    }
   ],
   "source": [
    "# count how many id that have both 'name' not equal to 'name_1' and reviewed = 'no'\n",
    "\n",
    "cur.execute(\"SELECT COUNT (*) FROM name_name1_not_equal INNER JOIN reviewed_is_no on \\\n",
    "            name_name1_not_equal.id = reviewed_is_no.id \")\n",
    "                     \n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the cases when reviewed = 'yes' and 'name' not equal to 'name_1' in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7148d810>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create view that contains all distinct id of reviewed = 'yes'\n",
    "cur.execute(\"CREATE VIEW reviewed_is_yes as\\\n",
    "            SELECT * FROM ways_tags WHERE ways_tags.key = 'reviewed' AND ways_tags.value = 'yes'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,)]\n"
     ]
    }
   ],
   "source": [
    "# count how many id that have both 'name' not equal to 'name_1' and reviewed = 'yes'\n",
    "\n",
    "cur.execute(\"SELECT COUNT (*) FROM name_name1_not_equal INNER JOIN reviewed_is_yes on \\\n",
    "            name_name1_not_equal.id = reviewed_is_yes.id \")\n",
    "                     \n",
    "results = cur.fetchall()\n",
    "pprint (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 67 cases that 'name' not equal to 'name_1', and 57 of them have that 'reviewed' = 'no'. The rest 10 cases don't show that 'reviewed' = 'yes' since we got 0 when count how many cases that have both 'name' not equal to 'name_1' and reviewed = 'yes'. Therefore I think we can improve the data quality by encouraging contributors to review data input when create it. In addition, we should also encourage contributors to create the 'reviewed' tag in case other contributors want to help review the data input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks that the tags 'node' and 'way' have different problems after exploration. The tags under the 'way' may have repeated or inconsistant attributes when 'k' includes 'tiger'. The 'node' tags have problems more like overabbreviated street names or nonstandard city name formats. We encourage contributors to double check data when the data comes from Tiger GPS and make notes of that in the attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Udacity's home page](https://www.udacity.com)\n",
    "\n",
    "[stackoverflow's home page](https://stackoverflow.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
